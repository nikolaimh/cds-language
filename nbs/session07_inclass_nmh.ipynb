{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX4n9TsbGw-f"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0nbI5DtDGw-i"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TnJztDZGw-n"
      },
      "source": [
        "# Text classification with an RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfN3bMR5Gw-o"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/text/tutorials/text_classification_rnn\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/text_classification_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/text_classification_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/text/docs/tutorials/text_classification_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUWearf0Gw-p"
      },
      "source": [
        "This text classification tutorial trains a [recurrent neural network](https://developers.google.com/machine-learning/glossary/#recurrent_neural_network) on the [IMDB large movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/) for sentiment analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2VQo4bajwUU"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z682XYsrjkY9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/coder/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-03-15 10:12:13.819939: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rXHa-w9JZhb"
      },
      "source": [
        "Import `matplotlib` and create a helper function to plot graphs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mp1Z7P9pYRSK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRmMubr0jrE2"
      },
      "source": [
        "## Setup input pipeline\n",
        "\n",
        "\n",
        "The IMDB large movie review dataset is a *binary classification* datasetâ€”all the reviews have either a *positive* or *negative* sentiment.\n",
        "\n",
        "Download the dataset using [TFDS](https://www.tensorflow.org/datasets). See the [loading text tutorial](https://www.tensorflow.org/tutorials/load_data/text) for details on how to load this sort of data manually.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SHRwRoP2nVHX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /home/coder/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-15 10:17:13.164244: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1mDataset imdb_reviews downloaded and prepared to /home/coder/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-15 10:17:50.337269: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "train_dataset.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWA4c2ir7g6p"
      },
      "source": [
        "Initially this returns a dataset of (text, label pairs):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vd4_BGKyurao"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
            "label:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-15 10:18:03.217420: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        }
      ],
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', label.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2qVJzcEluH_"
      },
      "source": [
        "Next shuffle the data for training and create batches of these `(text, label)` pairs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dDsCaZCDYZgm"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VznrltNOnUc5"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jqkvdcFv41wC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "texts:  [b'If you \"get it\", it\\'s magnificent.<br /><br />If you don\\'t, it\\'s decent.<br /><br />Please understand that \"getting it\" does not necessarily mean you\\'ve gone through a school shooting. There is so much more to this movie that, at times, the school shooting becomes insignificant.<br /><br />Above all, it\\'s a movie about acceptance, both superficially--of a traumatic event, but also of people who are different for whatever reason.<br /><br />It\\'s also a movie about unendurable pain, and how different people endure it. In this case, the contrast between Alicia\\'s rage and Deanna\\'s obsession creates an atmosphere of such palpable anxiety that halfway through the movie we wonder how the director could possibly pull a happy ending out of his hat. Thankfully, the audience is given credit for being human beings; our intelligence is not insulted by a sappy, implausibly moralistic ending.<br /><br />Above and beyond that, I try to keep a clear head about movies being fiction and all that. Yet I must admit, I cried like a lost little baby during this movie. There were certain things about it that hit *very* close to home and opened up some old wounds that never quite healed. But that is not necessarily a bad thing.'\n",
            " b'-A very pretty red headed woman waiting for her plane meets a charming young man that she connects with. As the two get on their flight and sit next to each other the young man Jack becomes deadly as he threatens Lisa to either change the room that a politician and his wife will be staying in, or else have her father die. See now that\\'s what you happens when you fly coach, stuff like that never happens in first class.<br /><br />-Other than having a conflict that takes place on a flight, the other thing that this movie shares with \"Flightplan\" is the sheer unbelievability *if that\\'s a word* of the story. The point of the whole is to get the main character to change a politician\\'s room so he can be assassinated which is a pretty plausible plan, but won\\'t it have being easier for Jack to just find someone that was computer savvy and have them hack into the hotel\\'s system? Teenagers today can damn near do anything with computers, so I\\'m pretty sure it would have been easier for him to simply get someone to change it using a computer instead of going through the trouble of spying on Lisa and getting her into the predicament that she lands on in the movie.<br /><br />-Plus one thing that struck me as odd was how no one on the plan heard a single thing they were talking about. This is a very small plane were talking about here and since their voices were raised occasionally it seems to me like the other passengers should have heard something. But I\\'m 100% sure that I\\'m reading way too much into it. The movie is meant to be as realistic as an episode of \"24\" so one can\\'t be perplexed by such complexities. For all my complaints though, this is still a very fun movie that gets the job done. It\\'s not exactly the type that requires to shut of your brain, but at the same time it doesn\\'t require great intelligence to fully enjoy.<br /><br />-I\\'d love to sit here in my comfy chair and rave about the brilliant acting in the movie but really I can\\'t. I love Rachel McAdams, I love Cillian Murphy, and I like Brian Cox, but they don\\'t really stretch their acting muscles here. It\\'s not really much of a problem since this isn\\'t the movie that studios hope to win multiple awards and the acting isn\\'t the least bit horrible, just not great. Wes Craven isn\\'t exactly the first that comes to mind when you think of a movie like this, but he does a very nice job considering the time they had to film the movie and the lack of depth to the script. It was definitely a huge improvement over the disappointing \"Cursed\" and as much as I liked him doing something different with this movie, I still would love for him to go back to doing what he did in the past which is great horror movies that is talked about decades after it\\'s release.<br /><br />-One nice thing about the movie which I really appreciated was just how short the movie was. It is great to sit and watch a nice three hour or so movie once in a while, but nowadays it\\'s like every movie that comes out feels too long, where as this movie just felt like the right length. Not too long, and too short. They don\\'t waste time by trying to develop the characters too much because they know this isn\\'t the movie for that and by doing so they made a very nice short movie. Being a huge film music geek, I have to say that the best part of the movie is the ultra cool score by Marco Beltrami. It\\'s really nice to see Beltrami go from writing the predictable stuff to the great music he\\'s doing now. I really the cool techno/orchestral stuff he does for the main titles. Too bad that I can\\'t find the soundtrack anywhere, would have really loved to listen to the titles anytime I wanted instead of having to pop in the DVD when I want to hear it.<br /><br />-Overall It\\'s nice for what it is and whiles it\\'s far from great cinema, should still provide for some small entertaining hour and a half'\n",
            " b'How can you sum up just exactly how feelgood and right and touching this film is?? For several weeks this DVD leaped off the shelf at me every time I went in the store - having seen Steve Carrell in a couple of films previously, I didn\\'t want to smear my thought process of him - so I resisted and resisted, until finally I grabbed it up with a \\'What the hell!\\' attitude! And how surprised was I! I just wish I had purchased it earlier. Having watched it three times in two days I am still smiling at how the portrayal of a widower struggling with three daughters, yearning for that which is missing since the passing of his beloved wife, who thus meets an intriguing woman, charming her in such a profound and interesting (dare I say bookish?) way, throws a whole different light onto life that makes him realize she is what he has been searching for.<br /><br />The snag of that woman being his brothers girl complicates matters - which portray Dan comically shy and with a heartfelt chagrin, seeing his \"someone special\" bringing such fun and enjoyment into the family home as well as his brothers life. You just really begin to feel for him.<br /><br />Then when the blind date occurs with Ruthie Draper - that is the turning point in Marie\\'s estimation of Dan!! The look she gives him when he repeats her comment, about not liking Ruthie - sheer Green-Eyed Monster! Triggering an absolutely hilarious scene as the two couples compete on the dance floor! This sequence is one of the most well-crafted as Dan starts to loosen up with regard to Marie.<br /><br />Other gut-wrenching scenes - Dan returns from the Book and Tackle Shop, confronted by his brothers, begins to describe what has just occurred....when Dan\\'s face drops it brings a sharp intake of breath!!<br /><br />His youngest daughter Lilly making the present celebrating their love for Suzanne, his late wife, brings a little heartfelt warmth and a little gulp as Dan realizes just what he has lost in life.<br /><br />When Dan plays guitar and sings at the Talent Show....his voice cracking slightly as he reprises the song....absolute gem! <br /><br />The acceptance of what occurs late in the film by his daughters...they all three love their father and want to see him happy, will not let him deny his love for Marie; the desperateness of Dan not to fail his daughters because he is their rock, their stronghold...and tell him so much more than that with just a few words.<br /><br />I could go on and on but I will leave it for now - maybe return and add more comments here in the near future....but I will end by saying....<br /><br />....if you want to watch a film that is just so damn good, with twists of comedy to lighten up the drama, that never feels forced or crass, that comes over as a genuine portrayal of a man discovering new life - not just with a woman but also with his extended family, then look no further.<br /><br />DAN IN REAL LIFE - 9 out of 10 for such a well-rendered cinematic experience with a score by Sondre Lerche, that intimately takes you there throughout whilst never being intrusive, with fine performances by the ensemble cast. I cannot wait to re-watch this again!!']\n",
            "\n",
            "labels:  [1 1 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-15 10:18:38.539549: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        }
      ],
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('texts: ', example.numpy()[:3])\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5eWCo88voPY"
      },
      "source": [
        "## Create the text encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFevcItw15P_"
      },
      "source": [
        "The raw text loaded by `tfds` needs to be processed before it can be used in a model. The simplest way to process text for training is using the `TextVectorization` layer. This layer has many capabilities, but this tutorial sticks to the default behavior.\n",
        "\n",
        "Create the layer, and pass the dataset's text to the layer's `.adapt` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uC25Lu1Yvuqy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/coder/.local/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/coder/.local/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuQzVBbe3Ldu"
      },
      "source": [
        "The `.adapt` method sets the layer's vocabulary. Here are the first 20 tokens. After the padding and unknown tokens they're sorted by frequency: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tBoyjjWg0Ac9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
              "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
              "      dtype='<U14')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjId5pua3jHQ"
      },
      "source": [
        "Once the vocabulary is set, the layer can encode text into indices. The tensors of indices are 0-padded to the longest sequence in the batch (unless you set a fixed `output_sequence_length`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RGc7C9WiwRWs"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 45,  23,  76, ...,   0,   0,   0],\n",
              "       [  4,  53, 179, ...,   0,   0,   0],\n",
              "       [ 87,  69,  23, ...,   0,   0,   0]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_example = encoder(example)[:3].numpy()\n",
        "encoded_example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5cjz0bS39IN"
      },
      "source": [
        "With the default settings, the process is not completely reversible. There are three main reasons for that:\n",
        "\n",
        "1. The default value for `preprocessing.TextVectorization`'s `standardize` argument is `\"lower_and_strip_punctuation\"`.\n",
        "2. The limited vocabulary size and lack of character-based fallback results in some unknown tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "N_tD0QY5wXaK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  b'If you \"get it\", it\\'s magnificent.<br /><br />If you don\\'t, it\\'s decent.<br /><br />Please understand that \"getting it\" does not necessarily mean you\\'ve gone through a school shooting. There is so much more to this movie that, at times, the school shooting becomes insignificant.<br /><br />Above all, it\\'s a movie about acceptance, both superficially--of a traumatic event, but also of people who are different for whatever reason.<br /><br />It\\'s also a movie about unendurable pain, and how different people endure it. In this case, the contrast between Alicia\\'s rage and Deanna\\'s obsession creates an atmosphere of such palpable anxiety that halfway through the movie we wonder how the director could possibly pull a happy ending out of his hat. Thankfully, the audience is given credit for being human beings; our intelligence is not insulted by a sappy, implausibly moralistic ending.<br /><br />Above and beyond that, I try to keep a clear head about movies being fiction and all that. Yet I must admit, I cried like a lost little baby during this movie. There were certain things about it that hit *very* close to home and opened up some old wounds that never quite healed. But that is not necessarily a bad thing.'\n",
            "Round-trip:  if you get it its [UNK] br if you dont its [UNK] br please understand that getting it does not [UNK] mean youve gone through a school [UNK] there is so much more to this movie that at times the school [UNK] becomes [UNK] br above all its a movie about [UNK] both [UNK] a [UNK] [UNK] but also of people who are different for whatever [UNK] br its also a movie about [UNK] [UNK] and how different people [UNK] it in this case the [UNK] between [UNK] [UNK] and [UNK] [UNK] [UNK] an atmosphere of such [UNK] [UNK] that [UNK] through the movie we wonder how the director could possibly [UNK] a happy ending out of his [UNK] [UNK] the audience is given [UNK] for being human [UNK] our [UNK] is not [UNK] by a [UNK] [UNK] [UNK] [UNK] br above and beyond that i try to keep a clear head about movies being [UNK] and all that yet i must admit i [UNK] like a lost little baby during this movie there were certain things about it that hit very close to home and [UNK] up some old [UNK] that never quite [UNK] but that is not [UNK] a bad thing                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
            "\n",
            "Original:  b'-A very pretty red headed woman waiting for her plane meets a charming young man that she connects with. As the two get on their flight and sit next to each other the young man Jack becomes deadly as he threatens Lisa to either change the room that a politician and his wife will be staying in, or else have her father die. See now that\\'s what you happens when you fly coach, stuff like that never happens in first class.<br /><br />-Other than having a conflict that takes place on a flight, the other thing that this movie shares with \"Flightplan\" is the sheer unbelievability *if that\\'s a word* of the story. The point of the whole is to get the main character to change a politician\\'s room so he can be assassinated which is a pretty plausible plan, but won\\'t it have being easier for Jack to just find someone that was computer savvy and have them hack into the hotel\\'s system? Teenagers today can damn near do anything with computers, so I\\'m pretty sure it would have been easier for him to simply get someone to change it using a computer instead of going through the trouble of spying on Lisa and getting her into the predicament that she lands on in the movie.<br /><br />-Plus one thing that struck me as odd was how no one on the plan heard a single thing they were talking about. This is a very small plane were talking about here and since their voices were raised occasionally it seems to me like the other passengers should have heard something. But I\\'m 100% sure that I\\'m reading way too much into it. The movie is meant to be as realistic as an episode of \"24\" so one can\\'t be perplexed by such complexities. For all my complaints though, this is still a very fun movie that gets the job done. It\\'s not exactly the type that requires to shut of your brain, but at the same time it doesn\\'t require great intelligence to fully enjoy.<br /><br />-I\\'d love to sit here in my comfy chair and rave about the brilliant acting in the movie but really I can\\'t. I love Rachel McAdams, I love Cillian Murphy, and I like Brian Cox, but they don\\'t really stretch their acting muscles here. It\\'s not really much of a problem since this isn\\'t the movie that studios hope to win multiple awards and the acting isn\\'t the least bit horrible, just not great. Wes Craven isn\\'t exactly the first that comes to mind when you think of a movie like this, but he does a very nice job considering the time they had to film the movie and the lack of depth to the script. It was definitely a huge improvement over the disappointing \"Cursed\" and as much as I liked him doing something different with this movie, I still would love for him to go back to doing what he did in the past which is great horror movies that is talked about decades after it\\'s release.<br /><br />-One nice thing about the movie which I really appreciated was just how short the movie was. It is great to sit and watch a nice three hour or so movie once in a while, but nowadays it\\'s like every movie that comes out feels too long, where as this movie just felt like the right length. Not too long, and too short. They don\\'t waste time by trying to develop the characters too much because they know this isn\\'t the movie for that and by doing so they made a very nice short movie. Being a huge film music geek, I have to say that the best part of the movie is the ultra cool score by Marco Beltrami. It\\'s really nice to see Beltrami go from writing the predictable stuff to the great music he\\'s doing now. I really the cool techno/orchestral stuff he does for the main titles. Too bad that I can\\'t find the soundtrack anywhere, would have really loved to listen to the titles anytime I wanted instead of having to pop in the DVD when I want to hear it.<br /><br />-Overall It\\'s nice for what it is and whiles it\\'s far from great cinema, should still provide for some small entertaining hour and a half'\n",
            "Round-trip:  a very pretty red [UNK] woman [UNK] for her [UNK] meets a [UNK] young man that she [UNK] with as the two get on their [UNK] and sit next to each other the young man jack becomes [UNK] as he [UNK] [UNK] to either change the room that a [UNK] and his wife will be [UNK] in or else have her father die see now thats what you happens when you [UNK] [UNK] stuff like that never happens in first [UNK] br other than having a [UNK] that takes place on a [UNK] the other thing that this movie [UNK] with [UNK] is the [UNK] [UNK] if thats a word of the story the point of the whole is to get the main character to change a [UNK] room so he can be [UNK] which is a pretty [UNK] [UNK] but wont it have being [UNK] for jack to just find someone that was [UNK] [UNK] and have them [UNK] into the [UNK] [UNK] [UNK] today can [UNK] near do anything with [UNK] so im pretty sure it would have been [UNK] for him to simply get someone to change it using a [UNK] instead of going through the [UNK] of [UNK] on [UNK] and getting her into the [UNK] that she [UNK] on in the moviebr br plus one thing that [UNK] me as [UNK] was how no one on the [UNK] heard a single thing they were talking about this is a very small [UNK] were talking about here and since their [UNK] were [UNK] [UNK] it seems to me like the other [UNK] should have heard something but im [UNK] sure that im reading way too much into it the movie is meant to be as realistic as an episode of [UNK] so one cant be [UNK] by such [UNK] for all my [UNK] though this is still a very fun movie that gets the job done its not exactly the type that [UNK] to [UNK] of your [UNK] but at the same time it doesnt [UNK] great [UNK] to [UNK] [UNK] br id love to sit here in my [UNK] [UNK] and [UNK] about the brilliant acting in the movie but really i cant i love [UNK] [UNK] i love [UNK] [UNK] and i like [UNK] [UNK] but they dont really [UNK] their acting [UNK] here its not really much of a problem since this isnt the movie that [UNK] hope to [UNK] [UNK] [UNK] and the acting isnt the least bit horrible just not great [UNK] [UNK] isnt exactly the first that comes to mind when you think of a movie like this but he does a very nice job [UNK] the time they had to film the movie and the lack of [UNK] to the script it was definitely a huge [UNK] over the [UNK] [UNK] and as much as i liked him doing something different with this movie i still would love for him to go back to doing what he did in the past which is great horror movies that is [UNK] about [UNK] after its [UNK] br one nice thing about the movie which i really [UNK] was just how short the movie was it is great to sit and watch a nice three hour or so movie once in a while but [UNK] its like every movie that comes out feels too long where as this movie just felt like the right [UNK] not too long and too short they dont waste time by trying to [UNK] the characters too much because they know this isnt the movie for that and by doing so they made a very nice short movie being a huge film music [UNK] i have to say that the best part of the movie is the [UNK] cool score by [UNK] [UNK] its really nice to see [UNK] go from writing the predictable stuff to the great music hes doing now i really the cool [UNK] stuff he does for the main [UNK] too bad that i cant find the soundtrack [UNK] would have really loved to [UNK] to the [UNK] [UNK] i wanted instead of having to [UNK] in the dvd when i want to hear itbr br overall its nice for what it is and [UNK] its far from great cinema should still [UNK] for some small entertaining hour and a half                                                                                                                                                                                                                                                                                \n",
            "\n",
            "Original:  b'How can you sum up just exactly how feelgood and right and touching this film is?? For several weeks this DVD leaped off the shelf at me every time I went in the store - having seen Steve Carrell in a couple of films previously, I didn\\'t want to smear my thought process of him - so I resisted and resisted, until finally I grabbed it up with a \\'What the hell!\\' attitude! And how surprised was I! I just wish I had purchased it earlier. Having watched it three times in two days I am still smiling at how the portrayal of a widower struggling with three daughters, yearning for that which is missing since the passing of his beloved wife, who thus meets an intriguing woman, charming her in such a profound and interesting (dare I say bookish?) way, throws a whole different light onto life that makes him realize she is what he has been searching for.<br /><br />The snag of that woman being his brothers girl complicates matters - which portray Dan comically shy and with a heartfelt chagrin, seeing his \"someone special\" bringing such fun and enjoyment into the family home as well as his brothers life. You just really begin to feel for him.<br /><br />Then when the blind date occurs with Ruthie Draper - that is the turning point in Marie\\'s estimation of Dan!! The look she gives him when he repeats her comment, about not liking Ruthie - sheer Green-Eyed Monster! Triggering an absolutely hilarious scene as the two couples compete on the dance floor! This sequence is one of the most well-crafted as Dan starts to loosen up with regard to Marie.<br /><br />Other gut-wrenching scenes - Dan returns from the Book and Tackle Shop, confronted by his brothers, begins to describe what has just occurred....when Dan\\'s face drops it brings a sharp intake of breath!!<br /><br />His youngest daughter Lilly making the present celebrating their love for Suzanne, his late wife, brings a little heartfelt warmth and a little gulp as Dan realizes just what he has lost in life.<br /><br />When Dan plays guitar and sings at the Talent Show....his voice cracking slightly as he reprises the song....absolute gem! <br /><br />The acceptance of what occurs late in the film by his daughters...they all three love their father and want to see him happy, will not let him deny his love for Marie; the desperateness of Dan not to fail his daughters because he is their rock, their stronghold...and tell him so much more than that with just a few words.<br /><br />I could go on and on but I will leave it for now - maybe return and add more comments here in the near future....but I will end by saying....<br /><br />....if you want to watch a film that is just so damn good, with twists of comedy to lighten up the drama, that never feels forced or crass, that comes over as a genuine portrayal of a man discovering new life - not just with a woman but also with his extended family, then look no further.<br /><br />DAN IN REAL LIFE - 9 out of 10 for such a well-rendered cinematic experience with a score by Sondre Lerche, that intimately takes you there throughout whilst never being intrusive, with fine performances by the ensemble cast. I cannot wait to re-watch this again!!'\n",
            "Round-trip:  how can you [UNK] up just exactly how [UNK] and right and [UNK] this film is for several [UNK] this dvd [UNK] off the [UNK] at me every time i went in the [UNK] having seen [UNK] [UNK] in a couple of films [UNK] i didnt want to [UNK] my thought [UNK] of him so i [UNK] and [UNK] until finally i [UNK] it up with a what the hell [UNK] and how surprised was i i just wish i had [UNK] it earlier having watched it three times in two days i am still [UNK] at how the [UNK] of a [UNK] [UNK] with three [UNK] [UNK] for that which is missing since the [UNK] of his [UNK] wife who [UNK] meets an [UNK] woman [UNK] her in such a [UNK] and interesting [UNK] i say [UNK] way [UNK] a whole different light [UNK] life that makes him realize she is what he has been [UNK] [UNK] br the [UNK] of that woman being his brothers girl [UNK] [UNK] which [UNK] [UNK] [UNK] [UNK] and with a [UNK] [UNK] seeing his someone special [UNK] such fun and [UNK] into the family home as well as his brothers life you just really begin to feel for [UNK] br then when the [UNK] [UNK] [UNK] with [UNK] [UNK] that is the [UNK] point in [UNK] [UNK] of [UNK] the look she gives him when he [UNK] her comment about not [UNK] [UNK] [UNK] [UNK] monster [UNK] an absolutely hilarious scene as the two [UNK] [UNK] on the dance [UNK] this sequence is one of the most [UNK] as [UNK] starts to [UNK] up with [UNK] to [UNK] br other [UNK] scenes [UNK] [UNK] from the book and [UNK] [UNK] [UNK] by his brothers begins to [UNK] what has just [UNK] [UNK] face [UNK] it brings a [UNK] [UNK] of [UNK] br his [UNK] daughter [UNK] making the present [UNK] their love for [UNK] his late wife brings a little [UNK] [UNK] and a little [UNK] as [UNK] [UNK] just what he has lost in [UNK] br when [UNK] plays [UNK] and [UNK] at the talent [UNK] voice [UNK] [UNK] as he [UNK] the [UNK] [UNK] br br the [UNK] of what [UNK] late in the film by his [UNK] all three love their father and want to see him happy will not let him [UNK] his love for [UNK] the [UNK] of [UNK] not to [UNK] his [UNK] because he is their rock their [UNK] tell him so much more than that with just a few [UNK] br i could go on and on but i will leave it for now maybe return and add more comments here in the near [UNK] i will end by [UNK] br if you want to watch a film that is just so [UNK] good with [UNK] of comedy to [UNK] up the drama that never feels forced or [UNK] that comes over as a [UNK] [UNK] of a man [UNK] new life not just with a woman but also with his [UNK] family then look no [UNK] br [UNK] in real life [UNK] out of 10 for such a [UNK] [UNK] experience with a score by [UNK] [UNK] that [UNK] takes you there throughout [UNK] never being [UNK] with fine performances by the [UNK] cast i cannot wait to [UNK] this again                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for n in range(3):\n",
        "  print(\"Original: \", example[n].numpy())\n",
        "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjUqGVBxGw-t"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7zsmInBOCPO"
      },
      "source": [
        "![A drawing of the information flow in the model](images/bidirectional.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgs6nnSTGw-t"
      },
      "source": [
        "Above is a diagram of the model. \n",
        "\n",
        "1. This model can be build as a `tf.keras.Sequential`.\n",
        "\n",
        "2. The first layer is the `encoder`, which converts the text to a sequence of token indices.\n",
        "\n",
        "3. After the encoder is an embedding layer. An embedding layer stores one vector per word. When called, it converts the sequences of word indices to sequences of vectors. These vectors are trainable. After training (on enough data), words with similar meanings often have similar vectors.\n",
        "\n",
        "  This index-lookup is much more efficient than the equivalent operation of passing a one-hot encoded vector through a `tf.keras.layers.Dense` layer.\n",
        "\n",
        "4. A recurrent neural network (RNN) processes sequence input by iterating through the elements. RNNs pass the outputs from one timestep to their input on the next timestep.\n",
        "\n",
        "  The `tf.keras.layers.Bidirectional` wrapper can also be used with an RNN layer. This propagates the input forward and backwards through the RNN layer and then concatenates the final output. \n",
        "\n",
        "  * The main advantage of a bidirectional RNN is that the signal from the beginning of the input doesn't need to be processed all the way through every timestep to affect the output.  \n",
        "\n",
        "  * The main disadvantage of a bidirectional RNN is that you can't efficiently stream predictions as words are being added to the end.\n",
        "\n",
        "5. After the RNN has converted the sequence to a single vector the two `layers.Dense` do some final processing, and convert from this vector representation to a single logit as the classification output. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4fodCI7soQi"
      },
      "source": [
        "The code to implement this is below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LwfoBkmRYcP3"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        # Use masking to handle the variable sequence lengths\n",
        "        mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIGmIGkkouUb"
      },
      "source": [
        "Please note that Keras sequential model is used here since all the layers in the model only have single input and produce single output. In case you want to use stateful RNN layer, you might want to build your model with Keras functional API or model subclassing so that you can retrieve and reuse the RNN layer states. Please check [Keras RNN guide](https://www.tensorflow.org/guide/keras/rnn#rnn_state_reuse) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF-PsCk1LwjY"
      },
      "source": [
        "The embedding layer [uses masking](https://www.tensorflow.org/guide/keras/masking_and_padding) to handle the varying sequence-lengths. All the layers after the `Embedding` support masking:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "87a8-CwfKebw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False, True, True, True, True]\n"
          ]
        }
      ],
      "source": [
        "print([layer.supports_masking for layer in model.layers])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlS0iaUIWLpI"
      },
      "source": [
        "To confirm that this works as expected, evaluate a sentence twice. First, alone so there's no padding to mask:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "O41gw3KfWHus"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "[-0.01917876]\n"
          ]
        }
      ],
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0VQmGnEWcuz"
      },
      "source": [
        "Now, evaluate it again in a batch with a longer sentence. The result should be identical:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIgpuTeFNDzq"
      },
      "outputs": [],
      "source": [
        "# predict on a sample text with padding\n",
        "\n",
        "padding = \"the \" * 2000\n",
        "predictions = model.predict(np.array([sample_text, padding]))\n",
        "print(predictions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRI776ZcH3Tf"
      },
      "source": [
        "Compile the Keras model to configure the training process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kj2xei41YZjC"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIwH3nto596k"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw86wWS4YgR2"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, epochs=10,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaNbXi43YgUT"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZmwt_mzaQJk"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.ylim(None, 1)\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history, 'loss')\n",
        "plt.ylim(0, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwSE_386uhxD"
      },
      "source": [
        "Run a prediction on a new sentence:\n",
        "\n",
        "If the prediction is >= 0.0, it is positive else it is negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXgfQSgRW6zU"
      },
      "outputs": [],
      "source": [
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g1evcaRpTKm"
      },
      "source": [
        "## Stack two or more LSTM layers\n",
        "\n",
        "Keras recurrent layers have two available modes that are controlled by the `return_sequences` constructor argument:\n",
        "\n",
        "* If `False` it returns only the last output for each input sequence (a 2D tensor of shape (batch_size, output_features)). This is the default, used in the previous model.\n",
        "\n",
        "* If `True` the full sequences of successive outputs for each timestep is returned (a 3D tensor of shape `(batch_size, timesteps, output_features)`).\n",
        "\n",
        "Here is what the flow of information looks like with `return_sequences=True`:\n",
        "\n",
        "![layered_bidirectional](images/layered_bidirectional.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbSClCrG1z8l"
      },
      "source": [
        "The interesting thing about using an `RNN` with `return_sequences=True` is that the output still has 3-axes, like the input, so it can be passed to another RNN layer, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo1jjO3vn0jo"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEPV5jVGp-is"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeSE-YjdqAeN"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_dataset, epochs=10,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LdwilM1qPM3"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykUKnAoqbycW"
      },
      "outputs": [],
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ('The movie was not good. The animation and the graphics '\n",
        "               'were terrible. I would not recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YYub0EDtwCu"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history, 'loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xvpE3BaGw_V"
      },
      "source": [
        "Check out other existing recurrent layers such as [GRU layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU).\n",
        "\n",
        "If you're interested in building custom RNNs, see the [Keras RNN Guide](https://www.tensorflow.org/guide/keras/rnn).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification_rnn.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
    },
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
